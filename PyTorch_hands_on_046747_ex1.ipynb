{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhPxNnYhUTu7ys6itd4dYQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomer9080/DL-Speech-exercises/blob/main/PyTorch_hands_on_046747_ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <img src=\"https://pytorch.org/assets/images/pytorch-logo.png\" alt=\"PyTorch\" width=\"40\"/> PyTorch Hands On"
      ],
      "metadata": {
        "id": "6nxJXg6ePz4z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the second part of our course, we'll focus on hands-on and advanced techniques for tackling different speech recognition tasks. Most modern systems rely on **deep neural networks (DNNs)**, which serve as the core of the algorithm.\n",
        "\n",
        "In this tutorial, you'll go through a **step-by-step process** to build a neural network that can classify different types of speech events. By the end, you'll know how to **import your data**, **prepare it for training**, and **feed it into a convolutional neural network (CNN)** to perform **speech classification** efficiently.\n",
        "\n",
        "* Note: Before you run your code, make sure your runtime uses a GPU and not CPU, for faster execution."
      ],
      "metadata": {
        "id": "imIVJITzQUwq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing python libraries"
      ],
      "metadata": {
        "id": "9_VuJ_EqSOda"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4369a928"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iQ_QybACPrhG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the data\n",
        "\n",
        "Before proceeding, we need to first load our data.\n",
        "Upload the data archive `speech_classification_ex1.tar.gz` attached in the moodle. Then unzip it using the command below:"
      ],
      "metadata": {
        "id": "n41wMnowSWmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip the downloaded file\n",
        "!tar -xzf speech_classification_ex1.tar.gz"
      ],
      "metadata": {
        "id": "bGMSv0YPSaTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocessing with the Torch `Dataset` Class\n",
        "\n",
        "Before feeding our data into the classifier, we first need to **preprocess** it.  \n",
        "In speech processing, we usually don’t pass the raw waveform directly into a neural network. Instead, we extract **acoustic features** such as **Spectrograms**, **MFCCs**, or **Log-Mel Spectrograms** that better represent the signal for learning.\n",
        "\n",
        "Don’t worry if these terms sound new — we’ll cover each of them later in the course.  \n",
        "For this exercise, we’ll use a **Log-Mel Spectrogram** as our input feature map.\n",
        "\n",
        "We’ll also use PyTorch’s `Dataset` class to conveniently load both the feature set (the sample **`X`**) and its corresponding label (**`y`**).\n",
        "\n",
        "Fill in the missing parts `( ... )` in the code cell below:\n"
      ],
      "metadata": {
        "id": "JAgE78DbcyuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "class SpeechDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, split=None, n_mels=80, n_fft=400, hop_length=160, padded_length_seconds=5):\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.sample_rate = 16000\n",
        "        self.data_frame = pd.read_csv(os.path.join(data_path, 'metadata.csv')) # Assuming a metadata.csv file\n",
        "\n",
        "        if split is not None:\n",
        "            self.data_frame = self.data_frame[self.data_frame['split'] == split].reset_index(drop=True) # Filter by split column\n",
        "\n",
        "        self.mel_spectrogram = torchaudio.transforms.MelSpectrogram(\n",
        "            n_mels=...,\n",
        "            n_fft=...,\n",
        "            hop_length=...,\n",
        "            sample_rate=...\n",
        "        )\n",
        "\n",
        "        self.padded_length_seconds = 5\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        audio_file_path = os.path.join(self.data_frame.loc[idx, 'wav_path'])\n",
        "        label = self.data_frame.loc[idx, 'class']\n",
        "\n",
        "        waveform, sample_rate = ... # Load audio file using torchaudio\n",
        "\n",
        "        # Pad waveform to fixed length\n",
        "        num_frames = ...\n",
        "        if waveform.shape[-1] < num_frames:\n",
        "            padding = ...\n",
        "            waveform = ...\n",
        "        else:\n",
        "            waveform = ...\n",
        "\n",
        "        # Do not change below !!!\n",
        "        mel_features = self.mel_spectrogram(waveform)[..., :-1] # Apply transformation to waveform\n",
        "\n",
        "        return mel_features, label"
      ],
      "metadata": {
        "id": "_XmEF2aaeeE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataloaders\n",
        "\n",
        "To train our model efficiently, we'll load the data in **mini-batches** using a **DataLoader**.  \n",
        "The DataLoader handles batching for us and lets us control important parameters like the **batch size**. It also helps us **read data efficiently from memory** during training, which becomes especially important when working with larger datasets.\n"
      ],
      "metadata": {
        "id": "sW9IXxT9gCvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "data_path = '...' # use page or endure\n",
        "\n",
        "train_dataset = SpeechDataset(data_path=data_path, split=\"...\")\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=2\n",
        ")\n",
        "\n",
        "val_dataset = SpeechDataset(data_path=data_path, split=\"...\")\n",
        "\n",
        "valloader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=2\n",
        ")"
      ],
      "metadata": {
        "id": "5F7NcFDCglWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining Our Model\n",
        "\n",
        "Next, we'll define a class called `MyClassifier`.  \n",
        "This class will contain two main parts:\n",
        "- The **network architecture**, defined inside the `__init__` method.\n",
        "- The **forward pass**, defined inside the `forward` method.\n",
        "\n",
        "Your task is to fill in the missing parts `( ... )` so that the network can handle inputs of shape **(B, C, M, T)**, where:\n",
        "- **B** — batch size  \n",
        "- **C** — number of channels (in our case, `C = 1`)  \n",
        "- **M** — number of bins in the log-Mel spectrogram  \n",
        "- **T** — time dimension\n"
      ],
      "metadata": {
        "id": "UIAX8e8JYut6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyClassifier(nn.Module):\n",
        "    def __init__(self, num_classes=2):\n",
        "        super(MyClassifier, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(..., 16, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(..., 128)\n",
        "        self.fc2 = nn.Linear(128, num_classes)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = ...  # Apply conv 1 and activation\n",
        "        x = ...  # Apply conv 2 and activation\n",
        "\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "\n",
        "        x = ...  # Apply FC1 and activation\n",
        "        x = ...  # Apply FC2\n",
        "        return x"
      ],
      "metadata": {
        "id": "F2pImybMZx2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try forwarding a single batch from our DataLoader through the model.  \n",
        "We'll take a look at the **input** and **output** shapes to make sure everything is working as expected.\n"
      ],
      "metadata": {
        "id": "Pc66Tf6photI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyClassifier()\n",
        "for mel_features, labels in trainloader:\n",
        "    print(f\"{mel_features.shape=}\")\n",
        "    output = model(mel_features)\n",
        "    print(f\"{output.shape=}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "zCm_ohmBh28i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure the **output** has the shape **(B, N)**, where **N** is the number of classes (in our case, `N = 2`).  \n",
        "The output (after applying normalization, such as the `softmax` function) represents the **probability distribution** for each sample, indicating the likelihood of belonging to each of the **N different classes**.\n"
      ],
      "metadata": {
        "id": "hAf_0BCJpgfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training\n",
        "\n",
        "Before we start training, we need to set up a **loss function** and an **optimizer**.  \n",
        "We'll also define a small helper function to **evaluate our model’s accuracy** during training.\n",
        "\n",
        "Since this is a **classification task**, we’ll use `nn.CrossEntropyLoss`.  \n",
        "Technically, since we’re dealing with **two classes**, we could also use `nn.BCELoss` (Binary Cross-Entropy Loss), but that would require a few changes in our network setup.\n",
        "\n",
        "For now, we’ll keep things simple and stick with `nn.CrossEntropyLoss`.\n"
      ],
      "metadata": {
        "id": "UG3P3oGXf8F_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.001\n",
        "num_epochs = 5\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = MyClassifier().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "9gORC4k4jJov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_accuracy(y_pred, y_true):\n",
        "    y_pred_softmax = torch.log_softmax(y_pred, dim=-1)\n",
        "    # Your code here\n",
        "    ...\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "yqC_SozcjVkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now proceed to train our network:"
      ],
      "metadata": {
        "id": "7eD-vh1CkPwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = ...\n",
        "\n",
        "    for i, (inputs, labels) in enumerate(...):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = ... # Model forward pass\n",
        "        loss = ... # Calculate loss\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += ... # aggregate loss (hint - use .item())\n",
        "\n",
        "        if (i + 1) % 3 == 0:  # Print every 3 mini-batches\n",
        "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(trainloader)}], Loss: {running_loss / 10:.4f}\")\n",
        "            running_loss = 0.0 # Reset running loss\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = ...\n",
        "    val_accuracy = ...\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in valloader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = ...\n",
        "            loss = ...\n",
        "\n",
        "            val_loss += ...\n",
        "            val_accuracy += ...\n",
        "\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Validation Loss: {val_loss / len(valloader):.4f}, Validation Accuracy: {val_accuracy / len(valloader):.4f}\")\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "id": "nnWCpflWkSYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Our Model\n",
        "\n",
        "Now that our model is trained, let's check how well it performs.  \n",
        "\n",
        "Complete the cell below so that it **runs predictions on the test DataLoader** and then **reports the accuracy** on the test set.\n"
      ],
      "metadata": {
        "id": "OsPgBY_8mE5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your evalutaion code here"
      ],
      "metadata": {
        "id": "QXZpaO7omx1n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "Great work! You’ve successfully implemented a **CNN-based classifier** to distinguish between different speech events.  \n",
        "\n",
        "Keep in mind that this is a **basic version** of a classifier. You can always make the network more powerful by **adding more convolutional layers**, incorporating **pooling techniques**, or experimenting with other architectural improvements.\n"
      ],
      "metadata": {
        "id": "XQyZphJZm1sK"
      }
    }
  ]
}