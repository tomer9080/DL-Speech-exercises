{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkWBILBM4z1ykKrhyEAS+K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tomer9080/DL-Speech-exercises/blob/main/griffin_lim_046747_ex3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spectrogram, MFCC, and the Griffinâ€“Lim Algorithm\n",
        "\n",
        "In this exercise, you will first implement functions to compute a spectrogram and extract MFCC features from a signal. Then, you will implement the **Griffinâ€“Lim algorithm** step by step for signal reconstruction.\n",
        "\n",
        "You may complete the exercise either locally or in a Google Colab environment.  \n",
        "If working locally, ensure that all required Python packages are properly installed.\n"
      ],
      "metadata": {
        "id": "fdi2F5rak4tH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import python libraries"
      ],
      "metadata": {
        "id": "ml--Lp3-lbb5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5s1chSFgkyaq"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "import torch\n",
        "import librosa\n",
        "import torchaudio\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import ShortTimeFFT"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the data\n",
        "\n",
        "Add to your environment (local or Colab) the audio signal attached to the assignment on the moodle site.\n",
        "\n",
        "You are encouraged to listen to the short clip ðŸ”‰ ðŸŽµ."
      ],
      "metadata": {
        "id": "K2O_4Mb2qDbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Audio\n",
        "\n",
        "audio_path = 'potatoes.flac'\n",
        "\n",
        "# Load and play the audio\n",
        "try:\n",
        "    audio_signal, sample_rate = librosa.load(audio_path, sr=16000)\n",
        "    display(Audio(audio_signal, rate=sample_rate))\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Audio file not found at '{audio_path}'\")"
      ],
      "metadata": {
        "id": "H8rhxo31Iiiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Spectrogram\n",
        "\n",
        "In this section, you will implement the `spectrogram` function.\n",
        "\n",
        "The function receives the following arguments:\n",
        "* `signal` â€” the input signal to be transformed into a spectrogram.  \n",
        "* `n_fft` â€” the window size of the spectrogram (in samples).  \n",
        "* `hop_length` â€” the number of samples between consecutive FFTs.  \n",
        "* `window` â€” the window function applied to each frame before the FFT.\n",
        "\n",
        "The function should return a single **real-valued** matrix called `spectrogram`, representing the magnitude spectrogram of the input `signal`.\n",
        "\n",
        "> **Note:** Do not use any built-in `stft` functions. You must implement it manually using `np.fft.fft`.\n"
      ],
      "metadata": {
        "id": "3n3Q0Wdzmkxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def spectrogram(signal: np.ndarray, n_fft: int, hop_length: int, window: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Computes the magnitude spectrogram of a signal from scratch using np.fft.fft.\n",
        "\n",
        "    Args:\n",
        "        signal (np.ndarray): The signal to be processed into a spectrogram.\n",
        "        n_fft (int): The window size of the spectrogram (in samples).\n",
        "        hop_length (int): How many samples between two consecutive FFTs.\n",
        "        window (np.ndarray): The window that is used to apply the transformation.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The magnitude spectrogram of the signal.\n",
        "    \"\"\"\n",
        "\n",
        "    return np.abs(spectrogram_matrix)"
      ],
      "metadata": {
        "id": "4qpzUBv4qi8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1 Evaluating the `spectrogram` Function\n",
        "\n",
        "In the following cell, perform the steps below:\n",
        "\n",
        "1. Load the provided audio signal.  \n",
        "2. Apply **your implementation** of the `spectrogram` function and store the result in a dedicated variable.  \n",
        "3. Apply **ShortTimeFFT.spectrogram** to the same signal and store the result in another variable.  \n",
        "4. Plot both spectrograms side by side for visual comparison.  \n",
        "5. Compute the L2 distance between the two spectrograms and include the value in your report.\n",
        "\n",
        "**Note:** For all subsequent sections in this exercise, use the following parameters:\n",
        "* `n_fft = 400`  \n",
        "* `hop_length = 160`  \n",
        "* `window = scipy.signal.windows.hann(n_fft)`  \n",
        "\n",
        "The provided signal is sampled at a rate of $16\\,\\text{kHz}$.\n"
      ],
      "metadata": {
        "id": "MhK5kl37sa9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "SUFPzYpyuQxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Log Mel-Spectrogram\n",
        "\n",
        "After implementing the basic spectrogram, you will now create a function called `transform_to_log_mel`.  \n",
        "This function should receive the following arguments:\n",
        "\n",
        "* `spectrogram` â€” the input spectrogram to be converted into a log mel-spectrogram.  \n",
        "* `n_mels` â€” the number of mel filters to apply in the transformation.  \n",
        "* `sample_rate` â€” the sampling rate of the signal.  \n",
        "* `n_fft` â€” the FFT window size used when computing the original spectrogram.\n",
        "\n",
        "The function should return a matrix named `log_mel_spec`, representing the log-scaled mel spectrogram of the input `spectrogram`.\n",
        "\n",
        "> **Note:** You can compute the mel filter bank using the `librosa.filters.mel` function.\n",
        "\n",
        "> **Note**: Make sure to avoid applying `log(0)` by adding $Ïµ$ to the mel spectrogram."
      ],
      "metadata": {
        "id": "4o2yw-y6rprm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_log_mel(spectrogram: np.ndarray, n_mels: int, sample_rate: int, n_fft: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Transforms a magnitude spectrogram to a log mel-spectrogram.\n",
        "\n",
        "    Args:\n",
        "        spectrogram (np.ndarray): The magnitude spectrogram.\n",
        "        n_mels (int): Number of mel filters.\n",
        "        sample_rate (int): The sample rate of the audio signal.\n",
        "        n_fft (int): The window size of the spectrogram (in samples).\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The log mel-spectrogram.\n",
        "    \"\"\"\n",
        "\n",
        "    return log_mel_spec"
      ],
      "metadata": {
        "id": "_iRrzWDjuaiy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Evaluating the `transform_to_log_mel` Function\n",
        "\n",
        "In the following cell, perform the steps below:\n",
        "\n",
        "1. Load the provided audio signal.  \n",
        "2. Apply **your implementation** of the `transform_to_log_mel` function on the spectrogram obtained in Section 1.1, and store the result in a dedicated variable.  \n",
        "3. Use **torchaudio.transforms.MelSpectrogram** to compute a log mel-spectrogram of the same signal, and store it in another variable.  \n",
        "4. Plot both log mel-spectrograms side by side for comparison.  \n",
        "5. Compute the L2 distance between the two log mel-spectrograms and include the result in your report.\n"
      ],
      "metadata": {
        "id": "IhewSV56uytK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "ZzkNdk6wvolW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. MFCC\n",
        "\n",
        "After obtaining the log-mel spectrogram, the next step is to extract **MFCC** (Mel-Frequency Cepstral Coefficients) features.\n",
        "\n",
        "Implement a function named `mfcc` that receives the following arguments:\n",
        "\n",
        "* `signal` â€” the input signal from which to extract MFCC features.  \n",
        "* `n_mfcc` â€” the number of MFCC coefficients to compute.  \n",
        "* `n_fft` â€” the FFT window size (in samples).  \n",
        "* `hop_length` â€” the number of samples between consecutive FFTs.  \n",
        "* `window` â€” the window function applied before each FFT.  \n",
        "* `n_mels` â€” the number of mel filters used to transform the spectrogram into a log-mel representation.\n",
        "\n",
        "The function should return a matrix named `mfcc_features`, containing the extracted MFCC features.\n",
        "\n",
        "> **Note**: To apply DCT, you can use `scipy.fftpack.dct`. Use `type=1`, and `norm='ortho'`"
      ],
      "metadata": {
        "id": "GfPi9pcvwW2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.fftpack\n",
        "\n",
        "def mfcc(signal: np.ndarray, n_mfcc: int, n_fft: int, hop_length: int, window: np.ndarray, n_mels: int, sample_rate: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Extracts MFCC features from a signal using previously implemented functions.\n",
        "\n",
        "    Args:\n",
        "        signal (np.ndarray): The signal to extract MFCC features from.\n",
        "        n_mfcc (int): Number of MFCC features to extract.\n",
        "        n_fft (int): The window size of the spectrogram (in samples).\n",
        "        hop_length (int): How many samples between two consecutive FFTs.\n",
        "        window (np.ndarray): The window that is used to apply the transformation.\n",
        "        n_mels (int): Number of mel filters used to transform the spectrogram to a log mel-spectrogram.\n",
        "        sample_rate (int): The sample rate of the audio signal.\n",
        "\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: The MFCC features.\n",
        "    \"\"\"\n",
        "\n",
        "    return mfcc_features"
      ],
      "metadata": {
        "id": "lM2B8iCYyyaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Evaluating the `mfcc` Function\n",
        "\n",
        "In the following cell, complete the steps below:\n",
        "\n",
        "1. Load the provided audio signal.  \n",
        "2. Apply **your implementation** of the `mfcc` function to the signal and store the output in a dedicated variable.  \n",
        "3. Use **torchaudio.transforms.MFCC** to compute the MFCC features for the same signal and store the result in another variable.  \n",
        "4. Plot both MFCC representations side by side and include the plots in your report.  \n",
        "5. Compute the L2 distance between the two MFCC feature matrices and include the result in your report.\n"
      ],
      "metadata": {
        "id": "xT-Sw3_iy8dL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "dXaWmQUs0bdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Griffinâ€“Lim Algorithm\n",
        "\n",
        "In this section, you will implement the **Griffinâ€“Lim algorithm** to reconstruct a time-domain signal from a real-valued spectrogram.\n",
        "\n",
        "The algorithm relies on the following iterative procedure:\n",
        "\n",
        "1. Initialize with a random phase (or zeros).  \n",
        "2. Form the complex spectrogram: $X_i = |S| e^{j \\phi}$.  \n",
        "3. Compute the inverse STFT to obtain the time-domain signal $x_i$.  \n",
        "4. Compute the STFT of $x_i$ to get a new spectrogram $X_{i+1}$.  \n",
        "5. Keep the original magnitude and update the phase: $\\Phi \\gets \\angle X_{i+1}$.  \n",
        "6. Repeat steps 3â€“5 for `n_iter` iterations.\n"
      ],
      "metadata": {
        "id": "zGsdy7rK0c_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implement a function named `griffin_lim` that takes the following arguments:\n",
        "\n",
        "* `magnitude` â€” the magnitude spectrogram from which to reconstruct the time-domain signal.  \n",
        "* `stft` â€” a `ShortTimeFFT` instance used for performing STFT and inverse STFT operations.  \n",
        "* `n_iter` â€” the number of iterations to run the Griffinâ€“Lim algorithm.  \n",
        "* `random_state` â€” an optional seed to ensure reproducible initialization of the phase.  \n",
        "* `init_phase` â€” an optional initial phase estimate, with the same shape as `magnitude`.\n",
        "\n",
        "The function should return the reconstructed time-domain signal, `reconstructed_signal`.\n"
      ],
      "metadata": {
        "id": "44vmh6XA_kdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def griffin_lim(magnitude, stft: ShortTimeFFT, n_iter=50, init_phase=None, random_state=None):\n",
        "    \"\"\"\n",
        "    Reconstructs a time-domain signal from a magnitude spectrogram using the Griffin-Lim algorithm.\n",
        "\n",
        "    Args:\n",
        "        magnitude (np.ndarray): Magnitude spectrogram, shape (n_frames, n_freq_bins)\n",
        "        stft (ShortTimeFFT): scipy.signal.ShortTimeFFT object (encapsulates stft/istft parameters)\n",
        "        n_iter (int): Number of Griffin-Lim iterations\n",
        "        init_phase (np.ndarray, optional): Optional initial phase estimate (same shape as magnitude)\n",
        "        random_state (int, optional): Seed for reproducibility when initializing phase\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Reconstructed time-domain signal\n",
        "    \"\"\"\n",
        "\n",
        "    return np.real(x_reconstructed)\n"
      ],
      "metadata": {
        "id": "0iz-bChN-WRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Evaluating the Griffinâ€“Lim Algorithm\n",
        "\n",
        "To evaluate your implementation of the Griffinâ€“Lim algorithm, follow the steps below:\n",
        "\n",
        "### Step 1: Reconstruction with Different Iterations\n",
        "1. Apply the `griffin_lim` function to the magnitude spectrogram of your signal using `n_iter` values of **10, 50, and 100**.  \n",
        "2. For each value of `n_iter`:\n",
        "   * Run once with a **random phase initialization** (`random_state=3407`).  \n",
        "   * Run once with **phase initialized to zeros** (`init_phase`).  \n",
        "3. Compare each reconstructed signal to the original signal:\n",
        "   * Compute the **L2 distance** and include it in your report.  \n",
        "   * Listen to the reconstructed signals and compare them with the original. Choose **two reconstructed signals** for detailed auditory comparison and describe any differences you hear.\n",
        "\n",
        "### Step 2: Spectrogram Comparison\n",
        "1. Select **two reconstructed signals** from Step 1.  \n",
        "2. Plot their spectrograms alongside the original signalâ€™s spectrogram.  \n",
        "3. Identify any visible differences and discuss them in your report.\n",
        "\n",
        "### Step 3: Comparison with `librosa.griffinlim`\n",
        "1. Apply `librosa.griffinlim` using the same parameters you selected in Step 2.  \n",
        "2. Compare the spectrograms of the three signals (your two reconstructions + `librosa` result) and note any differences.  \n",
        "3. Listen to all three signals and report any audible differences.\n"
      ],
      "metadata": {
        "id": "JhFXghcCCxL5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your code here"
      ],
      "metadata": {
        "id": "ugeRWl3EGFWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusions\n",
        "\n",
        "In this exercise, you implemented functions to compute a **spectrogram** and a **log-mel spectrogram**, and used these representations to extract **MFCC features** from a signal. These steps focused on transforming a signal from the **time domain to the frequency domain**.  \n",
        "\n",
        "To complete the task, you implemented the **Griffinâ€“Lim algorithm**, which performs the inverse operationâ€”reconstructing a time-domain signal from a **magnitude spectrogram**.\n"
      ],
      "metadata": {
        "id": "IfjMjVu57OIh"
      }
    }
  ]
}